{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE1BHRAe1xPq"
      },
      "source": [
        "# Install the New Worker- BETA!!\n",
        "### Remember to first set your API KEY and worker name\n",
        "#### You can serve different models, simply change the name in models_to_load to match the model you want, you can check either https://aqualxx.github.io/stable-ui/workers, in the models tab, or https://tinybots.net/artbot/info/models, just copy paste the name (it's set to Deliberate by default)\n",
        "#### You can also change max_power and see how high you can go, it's set to 20 by default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-20T23:06:35.113455Z",
          "iopub.status.busy": "2023-10-20T23:06:35.112701Z"
        },
        "id": "qHYIcsqJ1xPs",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#0.- This cell will set the variables and rerun the worker if you stopped it, but only if everything else was installed already\n",
        "\n",
        "#### For right now, THESE are the only variables that we care about\n",
        "worker_name = \"\"\n",
        "api_key = \"\"\n",
        "max_power = 20\n",
        "safety_on_gpu = True\n",
        "models_to_load = [\"Deliberate\"]\n",
        "allow_lora = True\n",
        "allow_controlnet = True\n",
        "nsfw = True\n",
        "censor_nsfw = False\n",
        "####For right now, THESE are the only variables that we care about\n",
        "\n",
        "\n",
        "queue_size = 1\n",
        "max_threads = 1\n",
        "horde_url = \"https://aihorde.net\"\n",
        "allow_painting = False\n",
        "dynamic_models = False\n",
        "models_to_skip = [\"stable_diffusion_inpainting\", \"stable_diffusion_2.1\",  \"stable_diffusion_2.0\"]\n",
        "allow_post_processing = False\n",
        "priority_usernames = []\n",
        "blacklist = []\n",
        "censorlist = []\n",
        "allow_img2img = True\n",
        "allow_unsafe_ip = True\n",
        "number_of_dynamic_models = 0\n",
        "max_models_to_download = 10\n",
        "forms = [\"caption\",\"nsfw\",\"interrogation\",\"post-process\"]\n",
        "\n",
        "\n",
        "current_path = \"/content/\"\n",
        "worker_path = current_path + \"horde-worker-reGen/\"\n",
        "bridgeData_file = worker_path + \"bridgeData.yaml\"\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(bridgeData_file):\n",
        "    print (\"bridgeData.yaml file not found. Proceed to install the worker.\")\n",
        "else:\n",
        "    print (\"bridgeData.yaml file found. Recreating bridgeData.yaml and restarting the worker.\")\n",
        "    create_yaml()\n",
        "    !cd /content\n",
        "    !source ../regen/bin/activate;python download_models.py\n",
        "    !cd /content\n",
        "    !source ../regen/bin/activate;python run_worker.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVecpjOM1xPu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#1.- Virtual Environment\n",
        "\n",
        "!apt-get update\n",
        "!apt install python3.10-venv\n",
        "!python -m venv regen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzwQDVd_1xPu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#2.- Remove the worker if it exists, then, Clone the regen worker\n",
        "\n",
        "!cd /content;rm -r horde-worker-reGen\n",
        "!cd /content;git clone https://github.com/Haidra-Org/horde-worker-reGen.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC4lce-51xPv",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#3.- Install requirements for cuda 11.8\n",
        "\n",
        "!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.118.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUSwcaXc1xPv",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#4.- Work around so hordelib installs @ cuda 11.8\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "!source regen/bin/activate;pip install -r .\\/horde-worker-reGen/requirements.hordelib.txt\n",
        "\n",
        "!source regen/bin/activate;pip install hordelib --no-deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-I1XNxx1xPv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#5.- Create .yaml config file\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "%cd $worker_path\n",
        "print (\"Creating bridgeData.yaml file.\")\n",
        "\n",
        "def create_yaml():\n",
        "\n",
        "    from yaml import load, dump\n",
        "\n",
        "    def make_yaml_sublist(list_to_convert: list[str]):\n",
        "        sublist_yaml = dump(list_to_convert)\n",
        "        sublist_yaml = \"\\n\" + sublist_yaml\n",
        "        return sublist_yaml\n",
        "\n",
        "\n",
        "\n",
        "    data = f\"\"\"horde_url: \"{horde_url}\"\n",
        "api_key: \"{api_key}\"\n",
        "priority_usernames: []\n",
        "max_threads: {max_threads}\n",
        "queue_size: {queue_size}\n",
        "safety_on_gpu: {safety_on_gpu}\n",
        "require_upfront_kudos: false\n",
        "dreamer_name: \"{worker_name}\"\n",
        "max_power: {max_power}\n",
        "nsfw: {nsfw.__str__().lower()}\n",
        "censor_nsfw: {censor_nsfw}\n",
        "blacklist: {blacklist}\n",
        "censorlist: {censorlist}\n",
        "allow_img2img: {allow_img2img.__str__().lower()}\n",
        "allow_painting: {allow_painting.__str__().lower()}\n",
        "allow_unsafe_ip: true\n",
        "allow_post_processing: {allow_post_processing.__str__().lower()}\n",
        "allow_controlnet: {allow_controlnet.__str__().lower()}\n",
        "allow_lora: {allow_lora.__str__().lower()}\n",
        "max_lora_cache_size: 10\n",
        "dynamic_models: false\n",
        "number_of_dynamic_models: 0\n",
        "max_models_to_download: 10\n",
        "stats_output_frequency: 30\n",
        "cache_home: \"./\"\n",
        "always_download: true\n",
        "temp_dir: \"./tmp\"\n",
        "disable_terminal_ui: True\n",
        "vram_to_leave_free: \"80%\"\n",
        "ram_to_leave_free: \"80%\"\n",
        "disable_disk_cache: false\n",
        "models_to_load: {make_yaml_sublist(models_to_load)}\n",
        "models_to_skip: {make_yaml_sublist(models_to_skip)}\n",
        "suppress_speed_warnings: false\n",
        "forms:\n",
        "- \"caption\"\n",
        "- \"nsfw\"\n",
        "- \"interrogation\"\n",
        "- \"post-process\"\n",
        "\"\"\"\n",
        "\n",
        "    with open(bridgeData_file, \"w\") as text_file:\n",
        "        text_file.write(data)\n",
        "\n",
        "    print (\"bridgeData.yaml file created.\")\n",
        "\n",
        "create_yaml()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwMyg3JN1xPv",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#6.- Run download models\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "!source ../regen/bin/activate;python download_models.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRnzqILb1xPw",
        "scrolled": true,
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#7.- Run the worker\n",
        "# Make sure you have the correct path based on any `cd` commands above\n",
        "!cd /content\n",
        "\n",
        "!source ../regen/bin/activate;python run_worker.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
